{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e810773-6a41-4663-bd94-f1789f808ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando video: FULL_pre55.mp4\n",
      "Analizando video: FULL_sr_8_5.mp4\n",
      "Error: Las dimensiones de la máscara no coinciden con las del video\n",
      "Analizando video: FULL_CLAHE_8_5.mp4\n",
      "Analizando video: FULL_post30.mp4\n",
      "Resultados guardados en metricas/piv_video_metrics.csv\n",
      "\n",
      "Resumen de resultados:\n",
      "\n",
      "Video: FULL_pre55.mp4\n",
      "  global_contrast_std_mean: 44.5868\n",
      "  global_contrast_std_var: 1.0610\n",
      "  global_contrast_range_mean: 254.2605\n",
      "  global_contrast_range_var: 1.2578\n",
      "  local_contrast_mean: 50.9174\n",
      "  local_contrast_var: 1.6340\n",
      "  illumination_uniformity_mean: 42.4930\n",
      "  illumination_uniformity_var: 1.3093\n",
      "  sharpness_mean: 514.4702\n",
      "  sharpness_var: 1728.6710\n",
      "  background_temporal_variance: 0\n",
      "  frame_count: 261\n",
      "\n",
      "Video: FULL_sr_8_5.mp4\n",
      "  global_contrast_std_mean: 49.0482\n",
      "  global_contrast_std_var: 0.6296\n",
      "  global_contrast_range_mean: 254.9272\n",
      "  global_contrast_range_var: 0.1824\n",
      "  local_contrast_mean: 48.9699\n",
      "  local_contrast_var: 0.2442\n",
      "  illumination_uniformity_mean: 43.8753\n",
      "  illumination_uniformity_var: 0.6263\n",
      "  sharpness_mean: 53.0926\n",
      "  sharpness_var: 165.5575\n",
      "  background_temporal_variance: 0\n",
      "  frame_count: 261\n",
      "\n",
      "Video: FULL_CLAHE_8_5.mp4\n",
      "  global_contrast_std_mean: 48.0911\n",
      "  global_contrast_std_var: 0.4328\n",
      "  global_contrast_range_mean: 254.7816\n",
      "  global_contrast_range_var: 0.2627\n",
      "  local_contrast_mean: 50.7944\n",
      "  local_contrast_var: 0.5955\n",
      "  illumination_uniformity_mean: 44.1451\n",
      "  illumination_uniformity_var: 0.6636\n",
      "  sharpness_mean: 1168.1142\n",
      "  sharpness_var: 9576.1059\n",
      "  background_temporal_variance: 0\n",
      "  frame_count: 261\n",
      "\n",
      "Video: FULL_post30.mp4\n",
      "  global_contrast_std_mean: 49.7424\n",
      "  global_contrast_std_var: 0.4482\n",
      "  global_contrast_range_mean: 254.8812\n",
      "  global_contrast_range_var: 0.1813\n",
      "  local_contrast_mean: 52.9702\n",
      "  local_contrast_var: 0.8348\n",
      "  illumination_uniformity_mean: 45.7548\n",
      "  illumination_uniformity_var: 0.6916\n",
      "  sharpness_mean: 1190.2611\n",
      "  sharpness_var: 10111.3772\n",
      "  background_temporal_variance: 0\n",
      "  frame_count: 261\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage import exposure\n",
    "from skimage.filters import laplace\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class PIVVideoAnalyzer:\n",
    "    \"\"\"\n",
    "    Clase para analizar videos y evaluar su idoneidad para análisis PIV\n",
    "    mediante el cálculo de métricas de calidad.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, videos_dir):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador con el directorio de videos.\n",
    "        \n",
    "        Args:\n",
    "            videos_dir (str): Ruta al directorio que contiene los videos a analizar\n",
    "        \"\"\"\n",
    "        self.videos_dir = videos_dir\n",
    "        self.results = {}\n",
    "    \n",
    "    def analyze_videos(self, roi_mask=None):\n",
    "        \"\"\"\n",
    "        Analiza todos los videos del directorio y calcula métricas de calidad.\n",
    "        \n",
    "        Args:\n",
    "            roi_mask (numpy.ndarray, optional): Máscara binaria que delimita la región de interés.\n",
    "                                              1 para la piscina, 0 para el fondo.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Diccionario con los resultados por video\n",
    "        \"\"\"\n",
    "        video_files = [f for f in os.listdir(self.videos_dir) \n",
    "                      if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "        \n",
    "        for video_file in video_files:\n",
    "            print(f\"Analizando video: {video_file}\")\n",
    "            video_path = os.path.join(self.videos_dir, video_file)\n",
    "            self.results[video_file] = self.analyze_single_video(video_path, roi_mask)\n",
    "            \n",
    "        return self.results\n",
    "    \n",
    "    def analyze_single_video(self, video_path, roi_mask=None):\n",
    "        \"\"\"\n",
    "        Analiza un único video y calcula las métricas de calidad.\n",
    "        \n",
    "        Args:\n",
    "            video_path (str): Ruta al archivo de video\n",
    "            roi_mask (numpy.ndarray, optional): Máscara binaria de la región de interés\n",
    "        \n",
    "        Returns:\n",
    "            dict: Diccionario con las métricas calculadas\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: No se pudo abrir el video {video_path}\")\n",
    "            return {}\n",
    "        \n",
    "        # Obtener información básica del video\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Inicializar resultados\n",
    "        metrics = {\n",
    "            'global_contrast_std': [],\n",
    "            'global_contrast_range': [],\n",
    "            'local_contrast': [],\n",
    "            'illumination_uniformity': [],\n",
    "            'sharpness': [],\n",
    "            'background_temporal_variance': []\n",
    "        }\n",
    "        \n",
    "        # Si no se proporciona máscara, crear una máscara por defecto (todo el frame es ROI)\n",
    "        if roi_mask is None:\n",
    "            roi_mask = np.ones((height, width), dtype=np.uint8)\n",
    "        elif roi_mask.shape[:2] != (height, width):\n",
    "            print(\"Error: Las dimensiones de la máscara no coinciden con las del video\")\n",
    "            roi_mask = cv2.resize(roi_mask, (width, height))\n",
    "        \n",
    "        # Matriz para almacenar valores temporales para cálculo de varianza de fondo\n",
    "        background_pixels = np.logical_not(roi_mask).astype(np.bool_)\n",
    "        if np.any(background_pixels):\n",
    "            temporal_values = []\n",
    "        \n",
    "        # Procesar cada frame\n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame_count >= total_frames:\n",
    "                break\n",
    "            \n",
    "            # Convertir a escala de grises si es necesario\n",
    "            if len(frame.shape) == 3:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray = frame\n",
    "            \n",
    "            # 1. Contraste Global\n",
    "            std_dev = np.std(gray)\n",
    "            value_range = np.max(gray) - np.min(gray)\n",
    "            metrics['global_contrast_std'].append(std_dev)\n",
    "            metrics['global_contrast_range'].append(value_range)\n",
    "            \n",
    "            # 2. Contraste Local usando CLAHE\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            clahe_img = clahe.apply(gray)\n",
    "            local_contrast = np.std(clahe_img)\n",
    "            metrics['local_contrast'].append(local_contrast)\n",
    "            \n",
    "            # 3. Uniformidad de Iluminación\n",
    "            grid_size = 16  # Dividir en una cuadrícula de 16x16\n",
    "            grid_h, grid_w = height // grid_size, width // grid_size\n",
    "            region_means = []\n",
    "            \n",
    "            for i in range(grid_size):\n",
    "                for j in range(grid_size):\n",
    "                    region = gray[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]\n",
    "                    region_means.append(np.mean(region))\n",
    "            \n",
    "            illumination_uniformity = np.std(region_means)\n",
    "            metrics['illumination_uniformity'].append(illumination_uniformity)\n",
    "            \n",
    "            # 4. Nitidez usando Laplaciano\n",
    "            laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "            sharpness = np.var(laplacian)\n",
    "            metrics['sharpness'].append(sharpness)\n",
    "            \n",
    "            # 5. Varianza temporal en regiones fuera de la piscina\n",
    "            if np.any(background_pixels):\n",
    "                background_values = gray[background_pixels]\n",
    "                temporal_values.append(np.mean(background_values))\n",
    "            \n",
    "            frame_count += 1\n",
    "        \n",
    "        # Calcular varianza temporal si hay píxeles de fondo\n",
    "        if np.any(background_pixels) and temporal_values:\n",
    "            metrics['background_temporal_variance'] = np.var(temporal_values)\n",
    "        else:\n",
    "            metrics['background_temporal_variance'] = 0\n",
    "        \n",
    "        # Calcular estadísticas agregadas para las métricas por frame\n",
    "        results = {\n",
    "            'global_contrast_std_mean': np.mean(metrics['global_contrast_std']),\n",
    "            'global_contrast_std_var': np.var(metrics['global_contrast_std']),\n",
    "            'global_contrast_range_mean': np.mean(metrics['global_contrast_range']),\n",
    "            'global_contrast_range_var': np.var(metrics['global_contrast_range']),\n",
    "            'local_contrast_mean': np.mean(metrics['local_contrast']),\n",
    "            'local_contrast_var': np.var(metrics['local_contrast']),\n",
    "            'illumination_uniformity_mean': np.mean(metrics['illumination_uniformity']),\n",
    "            'illumination_uniformity_var': np.var(metrics['illumination_uniformity']),\n",
    "            'sharpness_mean': np.mean(metrics['sharpness']),\n",
    "            'sharpness_var': np.var(metrics['sharpness']),\n",
    "            'background_temporal_variance': metrics['background_temporal_variance'],\n",
    "            'frame_count': frame_count\n",
    "        }\n",
    "        \n",
    "        cap.release()\n",
    "        return results\n",
    "    \n",
    "    def save_results(self, output_dir):\n",
    "        \"\"\"\n",
    "        Guarda los resultados en un archivo CSV y genera gráficos comparativos.\n",
    "        \n",
    "        Args:\n",
    "            output_dir (str): Directorio donde guardar los resultados\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No hay resultados para guardar\")\n",
    "            return\n",
    "        \n",
    "        # Crear directorio si no existe\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Convertir resultados a DataFrame\n",
    "        results_df = pd.DataFrame.from_dict(self.results, orient='index')\n",
    "        \n",
    "        # Guardar como CSV\n",
    "        csv_path = os.path.join(output_dir, 'piv_video_metrics.csv')\n",
    "        results_df.to_csv(csv_path)\n",
    "        print(f\"Resultados guardados en {csv_path}\")\n",
    "        \n",
    "        # Generar gráficos comparativos\n",
    "        self._generate_comparison_plots(results_df, output_dir)\n",
    "    \n",
    "    def _generate_comparison_plots(self, df, output_dir):\n",
    "        \"\"\"\n",
    "        Genera gráficos comparativos para las métricas principales.\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame con los resultados\n",
    "            output_dir (str): Directorio donde guardar los gráficos\n",
    "        \"\"\"\n",
    "        # Métricas para graficar\n",
    "        metrics_to_plot = [\n",
    "            'global_contrast_std_mean', \n",
    "            'local_contrast_mean', \n",
    "            'illumination_uniformity_mean',\n",
    "            'sharpness_mean', \n",
    "            'background_temporal_variance'\n",
    "        ]\n",
    "        \n",
    "        # Crear un gráfico de barras para cada métrica\n",
    "        for metric in metrics_to_plot:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            df[metric].plot(kind='bar', color='skyblue')\n",
    "            plt.title(f'Comparación de {metric}')\n",
    "            plt.ylabel('Valor')\n",
    "            plt.xlabel('Video')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f'{metric}_comparison.png'))\n",
    "            plt.close()\n",
    "        \n",
    "        # Crear un gráfico de radar para comparar todas las métricas normalizadas\n",
    "        self._create_radar_chart(df, metrics_to_plot, output_dir)\n",
    "    \n",
    "    def _create_radar_chart(self, df, metrics, output_dir):\n",
    "        \"\"\"\n",
    "        Crea un gráfico de radar para comparar todas las métricas normalizadas.\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): DataFrame con los resultados\n",
    "            metrics (list): Lista de métricas a incluir en el radar\n",
    "            output_dir (str): Directorio donde guardar el gráfico\n",
    "        \"\"\"\n",
    "        # Normalizar las métricas\n",
    "        df_norm = df.copy()\n",
    "        for metric in metrics:\n",
    "            if df[metric].max() > 0:\n",
    "                df_norm[metric] = df[metric] / df[metric].max()\n",
    "        \n",
    "        # Configurar el gráfico de radar\n",
    "        n_videos = len(df)\n",
    "        if n_videos > 0:\n",
    "            n_metrics = len(metrics)\n",
    "            angles = np.linspace(0, 2*np.pi, n_metrics, endpoint=False).tolist()\n",
    "            angles += angles[:1]  # Cerrar el círculo\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "            \n",
    "            # Dibujar para cada video\n",
    "            for i, video in enumerate(df.index):\n",
    "                values = df_norm.loc[video, metrics].values.tolist()\n",
    "                values += values[:1]  # Cerrar el círculo\n",
    "                \n",
    "                ax.plot(angles, values, linewidth=2, linestyle='solid', label=video)\n",
    "                ax.fill(angles, values, alpha=0.1)\n",
    "            \n",
    "            # Configurar etiquetas y leyenda\n",
    "            ax.set_theta_offset(np.pi / 2)\n",
    "            ax.set_theta_direction(-1)\n",
    "            ax.set_xticks(angles[:-1])\n",
    "            ax.set_xticklabels([m.replace('_', ' ') for m in metrics])\n",
    "            \n",
    "            plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "            plt.title('Comparación de métricas normalizadas', size=15)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(os.path.join(output_dir, 'radar_comparison.png'))\n",
    "            plt.close()\n",
    "\n",
    "def create_roi_mask(frame_shape, roi_coordinates=None):\n",
    "    \"\"\"\n",
    "    Crea una máscara de la región de interés (ROI).\n",
    "    \n",
    "    Args:\n",
    "        frame_shape (tuple): Forma del frame (alto, ancho)\n",
    "        roi_coordinates (list, optional): Lista de coordenadas (x, y) que definen el polígono ROI\n",
    "                                         Si es None, se asume todo el frame como ROI.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Máscara binaria donde 1 representa la ROI\n",
    "    \"\"\"\n",
    "    height, width = frame_shape\n",
    "    \n",
    "    if roi_coordinates is None:\n",
    "        # Si no se proporcionan coordenadas, todo el frame es ROI\n",
    "        return np.ones((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Crear máscara a partir de coordenadas de polígono\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    roi_coords = np.array(roi_coordinates, dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [roi_coords], 1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el análisis de videos PIV.\n",
    "    \"\"\"\n",
    "    # Configuración\n",
    "    videos_dir = 'videos'\n",
    "    output_dir = 'metricas'\n",
    "    \n",
    "    # Ejemplo de coordenadas ROI (reemplazar con las reales)\n",
    "    # Formato: [(x1, y1), (x2, y2), ...]\n",
    "    roi_coordinates = None  # Por defecto, todo el frame es ROI\n",
    "    \n",
    "    # Crear un analizador de videos\n",
    "    analyzer = PIVVideoAnalyzer(videos_dir)\n",
    "    \n",
    "    # Crear máscara ROI (opcional)\n",
    "    # Para esto necesitamos obtener primero las dimensiones de un frame\n",
    "    sample_video = [f for f in os.listdir(videos_dir) \n",
    "                   if f.endswith(('.mp4', '.avi', '.mov'))][0]\n",
    "    cap = cv2.VideoCapture(os.path.join(videos_dir, sample_video))\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        # Crear máscara con las dimensiones del frame\n",
    "        if len(frame.shape) == 3:\n",
    "            frame_shape = (frame.shape[0], frame.shape[1])\n",
    "        else:\n",
    "            frame_shape = frame.shape\n",
    "            \n",
    "        roi_mask = create_roi_mask(frame_shape, roi_coordinates)\n",
    "        \n",
    "        # Analizar videos\n",
    "        results = analyzer.analyze_videos(roi_mask)\n",
    "        \n",
    "        # Guardar y visualizar resultados\n",
    "        analyzer.save_results(output_dir)\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(\"\\nResumen de resultados:\")\n",
    "        for video, metrics in results.items():\n",
    "            print(f\"\\nVideo: {video}\")\n",
    "            for metric, value in metrics.items():\n",
    "                print(f\"  {metric}: {value:.4f}\" if isinstance(value, float) else f\"  {metric}: {value}\")\n",
    "    else:\n",
    "        print(\"Error: No se pudo leer el primer frame para determinar las dimensiones\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc23a7-84e8-4d33-ad2d-4ce0f9df2bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
