{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46db4170-b83a-4b8b-99e6-08c9aaca7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos los frames de un proceso anterior para limpiar las carpetas\n",
    "!rm -rf inputs/*\n",
    "!rm -rf resultados_threshold_pre/*\n",
    "!rm -rf resultados_CLAHE/*\n",
    "!rm -rf resultados_threshold_post/*\n",
    "!rm -rf results/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201b3632-1e51-4f13-96da-837cd455d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "# Funciones\n",
    "#########################################################################################\n",
    "  \n",
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "import glob # libreria para buscar los archivos a procesar\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def frames_to_video(input_folder, output_file='output.mp4', fps=30, frame_pattern='frame_*.jpg'):\n",
    "    \"\"\"\n",
    "    Convierte una secuencia de imágenes (frames) a un archivo de video MP4.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Ruta a la carpeta que contiene las imágenes\n",
    "        output_file (str): Nombre del archivo de salida (default: 'output.mp4')\n",
    "        fps (int): Frames por segundo del video resultante (default: 30)\n",
    "        frame_pattern (str): Patrón para buscar los archivos de frames (default: 'frame_*.jpg')\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si la conversión fue exitosa, False en caso contrario\n",
    "    \"\"\"\n",
    "    # Obtener la lista de todos los frames en la carpeta\n",
    "    frames_path = os.path.join(input_folder, frame_pattern)\n",
    "    frames = sorted(glob.glob(frames_path), key=lambda x: int(re.findall(r'\\d+', os.path.basename(x))[0]))\n",
    "    \n",
    "    if not frames:\n",
    "        print(f\"No se encontraron frames con el patrón {frame_pattern} en {input_folder}\")\n",
    "        return False\n",
    "    \n",
    "    # Leer el primer frame para obtener las dimensiones\n",
    "    frame = cv2.imread(frames[0])\n",
    "    if frame is None:\n",
    "        print(f\"No se pudo leer el frame: {frames[0]}\")\n",
    "        return False\n",
    "    \n",
    "    height, width, layers = frame.shape\n",
    "    \n",
    "    # Definir el codec y crear el objeto VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec MP4\n",
    "    video = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Agregar cada frame al video\n",
    "    for frame_file in frames:\n",
    "        frame = cv2.imread(frame_file)\n",
    "        if frame is not None:\n",
    "            video.write(frame)\n",
    "        else:\n",
    "            print(f\"Error al leer el frame: {frame_file}\")\n",
    "    \n",
    "    # Liberar el objeto VideoWriter\n",
    "    video.release()\n",
    "    print(f\"Video creado exitosamente: {output_file}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def recorte_auto(input_video_path, output_folder, output_video_path, umbral):\n",
    "    \"\"\"\n",
    "    Procesa un video de una piscina de metal fundido en movimiento horizontal,\n",
    "    detecta los límites vertical y horizontal donde aparece la piscina entre el\n",
    "    primer y último frame, recorta todos los frames a estos límites y \n",
    "    genera un nuevo video.\n",
    "    \n",
    "    Args:\n",
    "        input_video_path: Ruta del video de entrada\n",
    "        output_folder: Carpeta donde guardar los frames recortados\n",
    "        output_video_path: Ruta donde guardar el video resultante\n",
    "        umbral: Valor de pixel que sirve como umbral entre 0 y 255 \n",
    "    \"\"\"\n",
    "    # Crear carpeta de salida si no existe\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Abrir el video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: No se pudo abrir el video {input_video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Obtener propiedades del video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"Procesando video: {frame_count} frames, {width}x{height} píxeles, {fps} FPS\")\n",
    "    \n",
    "    # Variables para almacenar los límites verticales\n",
    "    min_y = height\n",
    "    max_y = 0\n",
    "    \n",
    "    # Variables para almacenar los límites horizontales\n",
    "    # Inicializamos con valores que garantizan que cubran toda la anchura inicialmente\n",
    "    min_x_global = width\n",
    "    max_x_global = 0\n",
    "    \n",
    "    # Primera pasada: Detectar contornos en todos los frames para determinar límites verticales\n",
    "    # print(\"Pasada 1: Detectando límites verticales...\")\n",
    "    \n",
    "    for _ in tqdm(range(frame_count)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convertir a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Aplicar umbral fijo de 60\n",
    "        _, thresh = cv2.threshold(gray, umbral, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Detectar contornos\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if contours:\n",
    "            # Elegir el contorno más grande (asumimos que es la piscina)\n",
    "            c = max(contours, key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            \n",
    "            # Actualizar los límites verticales globales\n",
    "            min_y = min(min_y, y)\n",
    "            max_y = max(max_y, y + h)\n",
    "    \n",
    "    # Reiniciar el video para detectar los límites horizontales en el primer y último frame\n",
    "    # print(\"Detectando límites horizontales en el primer y último frame...\")\n",
    "    cap.release()\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    # Obtener primer frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el primer frame\")\n",
    "        return\n",
    "    \n",
    "    # Procesar primer frame para obtener límites horizontales\n",
    "    gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, umbral, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        min_x_first = x\n",
    "        max_x_first = x + w\n",
    "        # print(f\"Límites horizontales en el primer frame: x_min={min_x_first}, x_max={max_x_first}\")\n",
    "    else:\n",
    "        min_x_first = 0\n",
    "        max_x_first = width\n",
    "    \n",
    "    # Posicionar en el último frame\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
    "    \n",
    "    # Obtener último frame\n",
    "    ret, last_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: No se pudo leer el último frame\")\n",
    "        return\n",
    "    \n",
    "    # Procesar último frame para obtener límites horizontales\n",
    "    gray = cv2.cvtColor(last_frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, umbral, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        min_x_last = x\n",
    "        max_x_last = x + w\n",
    "        # print(f\"Límites horizontales en el último frame: x_min={min_x_last}, x_max={max_x_last}\")\n",
    "    else:\n",
    "        min_x_last = 0\n",
    "        max_x_last = width\n",
    "    \n",
    "    # Determinar los límites horizontales globales\n",
    "    # Extendemos la región para que incluya la posición de la piscina tanto en el inicio como en el final\n",
    "    min_x_global = min(min_x_first, min_x_last)\n",
    "    max_x_global = max(max_x_first, max_x_last)\n",
    "    \n",
    "    # Añadir un margen de seguridad\n",
    "    margin = 3\n",
    "    min_y = max(0, min_y - margin)\n",
    "    max_y = min(height - 1, max_y + margin)\n",
    "    min_x_global = max(0, min_x_global - margin)\n",
    "    max_x_global = min(width - 1, max_x_global + margin)\n",
    "    \n",
    "    # print(f\"Límites finales para recorte: y_min={min_y}, y_max={max_y}, x_min={min_x_global}, x_max={max_x_global}\")\n",
    "    \n",
    "    # Reiniciar el video para la tercera pasada (recorte y guardado)\n",
    "    cap.release()\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    # Tercera pasada: recortar y guardar los frames\n",
    "    # print(\"Pasada 3: Recortando frames y guardando...\")\n",
    "    \n",
    "    # Dimensiones del frame recortado\n",
    "    new_height = max_y - min_y + 1\n",
    "    new_width = max_x_global - min_x_global + 1\n",
    "    \n",
    "    # Preparar el escritor de video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (new_width, new_height))\n",
    "    \n",
    "    frame_number = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Recortar el frame según los límites detectados\n",
    "        cropped_frame = frame[min_y:max_y+1, min_x_global:max_x_global+1]\n",
    "\n",
    "        # Redimensionar para mantener una salida de tamaño constante\n",
    "        #cropped_frame = cv2.resize(cropped_frame, (width, height))\n",
    "        \n",
    "        # Guardar el frame recortado\n",
    "        output_path = os.path.join(output_folder, f\"frame_{frame_number:04d}.jpg\")\n",
    "        cv2.imwrite(output_path, cropped_frame)\n",
    "        \n",
    "        # Añadir al video de salida\n",
    "        out.write(cropped_frame)\n",
    "        \n",
    "        frame_number += 1\n",
    "    \n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Recorte completado.\\n\")\n",
    "    # print(f\"Dimensiones del recorte: {new_width}x{new_height} píxeles\")\n",
    "    # print(f\"Video guardado en: {output_video_path}\")\n",
    "    # print(f\"Frames guardados en: {output_folder}\")\n",
    "\n",
    "\n",
    "def umbral(input_folder, output_folder, umbral_pre):\n",
    "    \"\"\"\n",
    "    Aplica filtro de umbralización para eliminar el ruido en las regiones fuera de la piscina\n",
    "\n",
    "    Args:\n",
    "    input_folder: ruta a carpeta con frames a procesar (string)\n",
    "    output_folder: ruta a carpeta con frames procesados (string)\n",
    "    umbral: valor de umbral entre 0 (negro) y 255 (blanco) (entero)\n",
    "    \"\"\"\n",
    "    # Crear la carpeta de salida si no existe\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Obtener la lista de archivos en la carpeta de entrada\n",
    "    # Se asume que las imágenes pueden tener extensión jpg, png, etc.\n",
    "    image_paths = glob.glob(os.path.join(input_folder, \"*.*\"))\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        # Leer la imagen en escala de grises\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"No se pudo cargar la imagen: {img_path}\")\n",
    "            continue\n",
    "    \n",
    "        # Aplicar el umbral TOZERO\n",
    "        # Los pixeles con valor menor a umbral2 se pondrán a 0 y los mayores se mantendrán\n",
    "        _, thresh_img = cv2.threshold(img, umbral_pre, 255, cv2.THRESH_TOZERO)\n",
    "    \n",
    "        # Generar la ruta de salida usando el mismo nombre de archivo\n",
    "        filename = os.path.basename(img_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "    \n",
    "        # Guardar la imagen procesada\n",
    "        cv2.imwrite(output_path, thresh_img)\n",
    "        #print(f\"Procesada y guardada: {output_path}\")\n",
    "    \n",
    "    print(\"Threshold completado.\")\n",
    "\n",
    "def CLAHE(input_folder, output_folder, tg, cl):\n",
    "    \"\"\"\n",
    "    Aplica ecualizaciones por bloques (kernel) y une los resultados \n",
    "    de cada bloque en una sola imagen con interpolacion en los bordes.\n",
    "\n",
    "    Args:\n",
    "    input_folder: ruta a carpeta con frames a procesar (string)\n",
    "    output_folder: ruta a carpeta con frames procesados (string)\n",
    "    tg: Tile Grid. Tamaño del kernel cuadrado de tg x tg (entero)\n",
    "    cl: Clip LImit. \n",
    "    \"\"\"\n",
    "    # input_folder = \"resultados_threshold\"\n",
    "    # output_folder = f\"resultados_CLAHE_{tg_cont}_{cl_cont}\"\n",
    "        \n",
    "    # Crear la carpeta de salida si no existe\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    # Crear objeto CLAHE con parámetros (clipLimit y tileGridSize pueden ajustarse)\n",
    "    clahe = cv2.createCLAHE(clipLimit=cl, tileGridSize=(tg, tg))\n",
    "        \n",
    "    # Obtener la lista de archivos de imagen en la carpeta de entrada\n",
    "    image_paths = glob.glob(os.path.join(input_folder, \"*.*\"))\n",
    "        \n",
    "    # Procesar cada imagen\n",
    "    for img_path in image_paths:\n",
    "        # Cargar la imagen\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"No se pudo cargar la imagen: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Convertir la imagen a escala de grises (CLAHE trabaja con imágenes en grises)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Aplicar CLAHE\n",
    "        processed = clahe.apply(gray)\n",
    "        \n",
    "        # Generar la ruta de salida manteniendo el mismo nombre de archivo\n",
    "        filename = os.path.basename(img_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # Guardar la imagen procesada\n",
    "        cv2.imwrite(output_path, processed)\n",
    "        #print(f\"Procesada y guardada: {output_path}\")\n",
    "        \n",
    "    print(\"CLAHE completado.\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06e2e88-0577-484e-862a-6d81be76a59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando video: 14108 frames, 1024x512 píxeles, 30.303030303030305 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14108/14108 [00:42<00:00, 334.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorte completado.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################\n",
    "# Recorte \n",
    "#########################################################################################\n",
    "  \n",
    "\n",
    "# Obtener la ruta del directorio de trabajo actual (normalmente es la carpeta donde se ejecuta el notebook)\n",
    "#directorio_actual = os.getcwd()\n",
    "input_video = \"/home/riemann007/Documentos/Proyecto CIDESI/polvo_completo_original.avi\" \n",
    "#output_frames_folder = os.path.join(directorio_actual,\"inputs\")\n",
    "output_frames_folder = \"inputs\"\n",
    "umbral_recorte = 70\n",
    "#output_video = os.path.join(directorio_actual,\"video_recortado_xy_pl3.mp4\")\n",
    "output_video = f\"/videos/FULL_umbral{umbral_recorte}_pl4.mp4\"\n",
    "\n",
    "\n",
    "# Procesar el video\n",
    "recorte_auto(input_video, output_frames_folder, output_video, umbral_recorte)\n",
    "\n",
    "frames_to_video(\"inputs\",\"/videos/recorte_FULL.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "503f826a-be61-405d-9ccf-e71143da56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold completado.\n",
      "Video creado exitosamente: videos/FULL_pre55.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################################\n",
    "# THRESHOLD preCLAHE\n",
    "#########################################################################################\n",
    "\n",
    "#PARAMETROS:\n",
    "umbral_pre = 55\n",
    "\n",
    "# Carpetas de entrada y salida\n",
    "input_folder = \"inputs\"\n",
    "output_folder = \"resultados_threshold_pre\"\n",
    "\n",
    "# Umbralización pre CLAHE\n",
    "umbral(input_folder, output_folder, umbral_pre)\n",
    "\n",
    "# Video para observar resultados\n",
    "ruta_frames = \"resultados_threshold_pre\"\n",
    "ruta_video = f\"videos/FULL_pre{umbral_pre}.mp4\"\n",
    "frames_to_video(ruta_frames, ruta_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8641ff-200b-43aa-8da7-198ff932fd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAHE completado.\n",
      "\n",
      "Video creado exitosamente: videos/FULL_CLAHE_8_5.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################################\n",
    "# CLAHE (Ecualizacion adaptativa) \n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "#PARAMETROS\n",
    "tg = 8 #Tile Grid: tamaño del kernel (kernel cuadrado)\n",
    "cl = 5 #CLip limit:\n",
    "\n",
    "# Carpetas de entrada y salida\n",
    "input_folder = \"resultados_threshold_pre\"\n",
    "output_folder = f\"resultados_CLAHE_{tg}_{cl}\"\n",
    "\n",
    "\n",
    "# Ecualizacion adaptativa (CLAHE)\n",
    "CLAHE(input_folder,output_folder, tg, cl)\n",
    "\n",
    "\n",
    "# Creacion de video CLAHE\n",
    "ruta_frames = f\"resultados_CLAHE_{tg}_{cl}\"\n",
    "ruta_video = f\"videos/FULL_CLAHE_{tg}_{cl}.mp4\"\n",
    "fps = 30\n",
    "        \n",
    "frames_to_video(ruta_frames, ruta_video, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eab8ebe-3a71-4856-b4f3-a3519e78a692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold completado.\n",
      "Video creado exitosamente: videos/FULL_post30.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################################################\n",
    "# THRESHOLD postCLAHE\n",
    "#########################################################################################\n",
    "\n",
    "#PARAMETROS:\n",
    "umbral_post = 30\n",
    "\n",
    "# Carpetas de entrada y salida\n",
    "input_folder = f\"resultados_CLAHE_{tg}_{cl}\"\n",
    "output_folder = \"resultados_threshold_post\"\n",
    "\n",
    "# Umbralización pre CLAHE\n",
    "umbral(input_folder, output_folder, umbral_post)\n",
    "\n",
    "# Video para observar resultados\n",
    "ruta_frames = \"resultados_threshold_post\"\n",
    "ruta_video = f\"videos/FULL_post{umbral_post}.mp4\"\n",
    "frames_to_video(ruta_frames, ruta_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb63729-0714-4867-84c7-1c2bc2c8c8dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1050\n",
      "/home/riemann007/miniconda3/envs/drct_env/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "DRCT(\n",
      "  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (patch_unembed): PatchUnEmbed()\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (1): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (2): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (3): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (4): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (5): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (6): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (7): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (8): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (9): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (10): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "    (11): RDG(\n",
      "      (swin1): SwinTransformerBlock(\n",
      "        dim=180, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=180, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=180, out_features=540, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=180, out_features=180, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=180, out_features=360, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=360, out_features=180, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin2): SwinTransformerBlock(\n",
      "        dim=212, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2\n",
      "        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=212, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=212, out_features=636, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=212, out_features=212, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=212, out_features=424, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=424, out_features=212, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin3): SwinTransformerBlock(\n",
      "        dim=244, input_resolution=(64, 64), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2\n",
      "        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=244, window_size=(16, 16), num_heads=2\n",
      "          (qkv): Linear(in_features=244, out_features=732, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=244, out_features=244, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=244, out_features=488, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=488, out_features=244, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin4): SwinTransformerBlock(\n",
      "        dim=276, input_resolution=(64, 64), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1\n",
      "        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=276, window_size=(16, 16), num_heads=6\n",
      "          (qkv): Linear(in_features=276, out_features=828, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=276, out_features=276, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (swin5): SwinTransformerBlock(\n",
      "        dim=308, input_resolution=(64, 64), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1\n",
      "        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): WindowAttention(\n",
      "          dim=308, window_size=(16, 16), num_heads=4\n",
      "          (qkv): Linear(in_features=308, out_features=924, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "        )\n",
      "        (drop_path): DropPath()\n",
      "        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (act): GELU(approximate=none)\n",
      "          (fc2): Linear(in_features=308, out_features=308, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (pe): PatchEmbed()\n",
      "      (pue): PatchUnEmbed()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_before_upsample): Sequential(\n",
      "    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (upsample): Upsample(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): PixelShuffle(upscale_factor=2)\n",
      "  )\n",
      "  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Testing 0 frame_0000\n",
      "Testing 1 frame_0001\n",
      "Testing 2 frame_0002\n",
      "Testing 3 frame_0003\n",
      "Testing 4 frame_0004\n",
      "Testing 5 frame_0005\n",
      "Testing 6 frame_0006\n",
      "Testing 7 frame_0007\n",
      "Testing 8 frame_0008\n",
      "Testing 9 frame_0009\n",
      "Testing 10 frame_0010\n",
      "Testing 11 frame_0011\n",
      "Testing 12 frame_0012\n",
      "Testing 13 frame_0013\n",
      "Testing 14 frame_0014\n",
      "Testing 15 frame_0015\n",
      "Testing 16 frame_0016\n",
      "Testing 17 frame_0017\n",
      "Testing 18 frame_0018\n",
      "Testing 19 frame_0019\n",
      "Testing 20 frame_0020\n",
      "Testing 21 frame_0021\n",
      "Testing 22 frame_0022\n",
      "Testing 23 frame_0023\n",
      "Testing 24 frame_0024\n",
      "Testing 25 frame_0025\n",
      "Testing 26 frame_0026\n",
      "Testing 27 frame_0027\n",
      "Testing 28 frame_0028\n",
      "Testing 29 frame_0029\n",
      "Testing 30 frame_0030\n",
      "Testing 31 frame_0031\n",
      "Testing 32 frame_0032\n",
      "Testing 33 frame_0033\n",
      "Testing 34 frame_0034\n",
      "Testing 35 frame_0035\n",
      "Testing 36 frame_0036\n",
      "Testing 37 frame_0037\n",
      "Testing 38 frame_0038\n",
      "Testing 39 frame_0039\n",
      "Testing 40 frame_0040\n",
      "Testing 41 frame_0041\n",
      "Testing 42 frame_0042\n",
      "Testing 43 frame_0043\n",
      "Testing 44 frame_0044\n",
      "Testing 45 frame_0045\n",
      "Testing 46 frame_0046\n",
      "Testing 47 frame_0047\n",
      "Testing 48 frame_0048\n",
      "Testing 49 frame_0049\n",
      "Testing 50 frame_0050\n",
      "Testing 51 frame_0051\n",
      "Testing 52 frame_0052\n",
      "Testing 53 frame_0053\n",
      "Testing 54 frame_0054\n",
      "Testing 55 frame_0055\n",
      "Testing 56 frame_0056\n",
      "Testing 57 frame_0057\n",
      "Testing 58 frame_0058\n",
      "Testing 59 frame_0059\n",
      "Testing 60 frame_0060\n",
      "Testing 61 frame_0061\n",
      "Testing 62 frame_0062\n",
      "Testing 63 frame_0063\n",
      "Testing 64 frame_0064\n",
      "Testing 65 frame_0065\n",
      "Testing 66 frame_0066\n",
      "Testing 67 frame_0067\n",
      "Testing 68 frame_0068\n",
      "Testing 69 frame_0069\n",
      "Testing 70 frame_0070\n",
      "Testing 71 frame_0071\n",
      "Testing 72 frame_0072\n",
      "Testing 73 frame_0073\n",
      "Testing 74 frame_0074\n",
      "Testing 75 frame_0075\n",
      "Testing 76 frame_0076\n",
      "Testing 77 frame_0077\n",
      "Testing 78 frame_0078\n",
      "Testing 79 frame_0079\n",
      "Testing 80 frame_0080\n",
      "Testing 81 frame_0081\n",
      "Testing 82 frame_0082\n",
      "Testing 83 frame_0083\n",
      "Testing 84 frame_0084\n",
      "Testing 85 frame_0085\n",
      "Testing 86 frame_0086\n",
      "Testing 87 frame_0087\n",
      "Testing 88 frame_0088\n",
      "Testing 89 frame_0089\n",
      "Testing 90 frame_0090\n",
      "Testing 91 frame_0091\n",
      "Testing 92 frame_0092\n",
      "Testing 93 frame_0093\n",
      "Testing 94 frame_0094\n",
      "Testing 95 frame_0095\n",
      "Testing 96 frame_0096\n",
      "Testing 97 frame_0097\n",
      "Testing 98 frame_0098\n",
      "Testing 99 frame_0099\n",
      "Testing 100 frame_0100\n",
      "Testing 101 frame_0101\n",
      "Testing 102 frame_0102\n",
      "Testing 103 frame_0103\n",
      "Testing 104 frame_0104\n",
      "Testing 105 frame_0105\n",
      "Testing 106 frame_0106\n",
      "Testing 107 frame_0107\n",
      "Testing 108 frame_0108\n",
      "Testing 109 frame_0109\n",
      "Testing 110 frame_0110\n",
      "Testing 111 frame_0111\n",
      "Testing 112 frame_0112\n",
      "Testing 113 frame_0113\n",
      "Testing 114 frame_0114\n",
      "Testing 115 frame_0115\n",
      "Testing 116 frame_0116\n",
      "Testing 117 frame_0117\n",
      "Testing 118 frame_0118\n",
      "Testing 119 frame_0119\n",
      "Testing 120 frame_0120\n",
      "Testing 121 frame_0121\n",
      "Testing 122 frame_0122\n",
      "Testing 123 frame_0123\n",
      "Testing 124 frame_0124\n",
      "Testing 125 frame_0125\n",
      "Testing 126 frame_0126\n",
      "Testing 127 frame_0127\n",
      "Testing 128 frame_0128\n",
      "Testing 129 frame_0129\n",
      "Testing 130 frame_0130\n",
      "Testing 131 frame_0131\n",
      "Testing 132 frame_0132\n",
      "Testing 133 frame_0133\n",
      "Testing 134 frame_0134\n",
      "Testing 135 frame_0135\n",
      "Testing 136 frame_0136\n",
      "Testing 137 frame_0137\n",
      "Testing 138 frame_0138\n",
      "Testing 139 frame_0139\n",
      "Testing 140 frame_0140\n",
      "Testing 141 frame_0141\n",
      "Testing 142 frame_0142\n",
      "Testing 143 frame_0143\n",
      "Testing 144 frame_0144\n",
      "Testing 145 frame_0145\n",
      "Testing 146 frame_0146\n",
      "Testing 147 frame_0147\n",
      "Testing 148 frame_0148\n",
      "Testing 149 frame_0149\n",
      "Testing 150 frame_0150\n",
      "Testing 151 frame_0151\n",
      "Testing 152 frame_0152\n",
      "Testing 153 frame_0153\n",
      "Testing 154 frame_0154\n",
      "Testing 155 frame_0155\n",
      "Testing 156 frame_0156\n",
      "Testing 157 frame_0157\n",
      "Testing 158 frame_0158\n",
      "Testing 159 frame_0159\n",
      "Testing 160 frame_0160\n",
      "Testing 161 frame_0161\n",
      "Testing 162 frame_0162\n",
      "Testing 163 frame_0163\n",
      "Testing 164 frame_0164\n",
      "Testing 165 frame_0165\n",
      "Testing 166 frame_0166\n",
      "Testing 167 frame_0167\n",
      "Testing 168 frame_0168\n",
      "Testing 169 frame_0169\n",
      "Testing 170 frame_0170\n",
      "Testing 171 frame_0171\n",
      "Testing 172 frame_0172\n",
      "Testing 173 frame_0173\n",
      "Testing 174 frame_0174\n",
      "Testing 175 frame_0175\n",
      "Testing 176 frame_0176\n",
      "Testing 177 frame_0177\n",
      "Testing 178 frame_0178\n",
      "Testing 179 frame_0179\n",
      "Testing 180 frame_0180\n",
      "Testing 181 frame_0181\n",
      "Testing 182 frame_0182\n",
      "Testing 183 frame_0183\n",
      "Testing 184 frame_0184\n",
      "Testing 185 frame_0185\n",
      "Testing 186 frame_0186\n",
      "Testing 187 frame_0187\n",
      "Testing 188 frame_0188\n",
      "Testing 189 frame_0189\n",
      "Testing 190 frame_0190\n",
      "Testing 191 frame_0191\n",
      "Testing 192 frame_0192\n",
      "Testing 193 frame_0193\n",
      "Testing 194 frame_0194\n",
      "Testing 195 frame_0195\n",
      "Testing 196 frame_0196\n",
      "Testing 197 frame_0197\n",
      "Testing 198 frame_0198\n",
      "Testing 199 frame_0199\n",
      "Testing 200 frame_0200\n",
      "Testing 201 frame_0201\n",
      "Testing 202 frame_0202\n",
      "Testing 203 frame_0203\n",
      "Testing 204 frame_0204\n",
      "Testing 205 frame_0205\n",
      "Testing 206 frame_0206\n",
      "Testing 207 frame_0207\n",
      "Testing 208 frame_0208\n",
      "Testing 209 frame_0209\n",
      "Testing 210 frame_0210\n",
      "Testing 211 frame_0211\n",
      "Testing 212 frame_0212\n",
      "Testing 213 frame_0213\n",
      "Testing 214 frame_0214\n",
      "Testing 215 frame_0215\n",
      "Testing 216 frame_0216\n",
      "Testing 217 frame_0217\n",
      "Testing 218 frame_0218\n",
      "Testing 219 frame_0219\n",
      "Testing 220 frame_0220\n",
      "Testing 221 frame_0221\n",
      "Testing 222 frame_0222\n",
      "Testing 223 frame_0223\n",
      "Testing 224 frame_0224\n",
      "Testing 225 frame_0225\n",
      "Testing 226 frame_0226\n",
      "Testing 227 frame_0227\n",
      "Testing 228 frame_0228\n",
      "Testing 229 frame_0229\n",
      "Testing 230 frame_0230\n",
      "Testing 231 frame_0231\n",
      "Testing 232 frame_0232\n",
      "Testing 233 frame_0233\n",
      "Testing 234 frame_0234\n",
      "Testing 235 frame_0235\n",
      "Testing 236 frame_0236\n",
      "Testing 237 frame_0237\n",
      "Testing 238 frame_0238\n",
      "Testing 239 frame_0239\n",
      "Testing 240 frame_0240\n",
      "Testing 241 frame_0241\n",
      "Testing 242 frame_0242\n",
      "Testing 243 frame_0243\n",
      "Testing 244 frame_0244\n",
      "Testing 245 frame_0245\n",
      "Testing 246 frame_0246\n",
      "Testing 247 frame_0247\n",
      "Testing 248 frame_0248\n",
      "Testing 249 frame_0249\n",
      "Testing 250 frame_0250\n",
      "Testing 251 frame_0251\n",
      "Testing 252 frame_0252\n",
      "Testing 253 frame_0253\n",
      "Testing 254 frame_0254\n",
      "Testing 255 frame_0255\n",
      "Testing 256 frame_0256\n",
      "Testing 257 frame_0257\n",
      "Testing 258 frame_0258\n",
      "Testing 259 frame_0259\n",
      "Testing 260 frame_0260\n",
      "No se encontraron frames con el patrón frame_*.jpg en results\n",
      "\n",
      "Aumento de resolución x4 realizada.\n",
      "\n",
      "\n",
      "Proceso terminado.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificamos disponibilidad de GPU\n",
    "\n",
    "print(torch.cuda.is_available())  # Imprime True si CUDA esta disponible\n",
    "print(torch.cuda.device_count())  # Muestra el número de GPUs disponibles\n",
    "print(torch.cuda.get_device_name(0))  # Muestra el modelo de GPU en caso de existir\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Super resolucion con modelo REal-ESRGAN\n",
    "#########################################################################################\n",
    "\n",
    "#Hace la inferencia (ejecuta el modelo para los frames del video en la carpeta llamada \"inputs\")\n",
    "\n",
    "#Si es en cpu usar esta linea y comentar la de abajo\n",
    "#!python inference_realesrgan.py -n RealESRGAN_x4plus -i resultados_threshold_post -dn 0\n",
    "\n",
    "#Si es en gpu nvidia usar esta linea y comentar la de arriba\n",
    "# !python inference_realesrgan.py -n RealESRGAN_x4plus -i resultados_threshold_post -dn 0 --fp32 --tile 200 --gpu-id 0\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Super resolucion con modelo DRCT \n",
    "#########################################################################################\n",
    "\n",
    "# Si detecta GPU carga el modelo directo en ella\n",
    "!python inference.py --input resultados_threshold_post --output results --model_path \"/home/riemann007/JupyterLab/Proyecto CIDESI/DRCT/drct/models/net_g_latest.pth\"\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Super resolucion con modelo RVRT\n",
    "#########################################################################################\n",
    "\n",
    "# !rm -r RVRT\n",
    "# # Clone RVRT\n",
    "# !git clone https://github.com/JingyunLiang/RVRT.git\n",
    "# %cd RVRT\n",
    "# !pip install -r requirements.txt \n",
    "\n",
    "\n",
    "# !python main_test_rvrt.py --task 001_RVRT_videosr_bi_REDS_30frames --folder_lq testsets/uploaded --tile 0 128 128 --tile_overlap 2 20 20 --num_workers 2 --save_result\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "# Video con super resolucion\n",
    "# frames_folder = os.path.join(directorio_actual, \"results\")  # Ruta a carpeta de frames\n",
    "frames_folder = \"results\"\n",
    "# output_path =  os.path.join(directorio_actual,\"videos/video_sr_auto_pl3.mp4\") # Ruta a carpeta de guardado y nombre del video\n",
    "output_path = f\"videos/FULL_sr_{tg}_{cl}.mp4\"\n",
    "frames_to_video(frames_folder, output_path, fps, frame_pattern='frame_*.png')\n",
    "\n",
    "print(\"\\nAumento de resolución x4 realizada.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nProceso terminado.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
